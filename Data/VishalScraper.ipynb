{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Vishal Dubey\n",
    "from bs4 import BeautifulSoup as soup  # HTML data structure\n",
    "from urllib.request import urlopen as uReq  # Web client\n",
    "import csv # for writing to csv\n",
    "from itertools import zip_longest # for zipping lists together\n",
    "\n",
    "\n",
    "# name the output file to write to local disk\n",
    "out_filename = \"fantasyPointsData.csv\"\n",
    "# header of csv file to be written\n",
    "headers = [\"name\", \"games\", \"points\", \"year\"]\n",
    "\n",
    "# opens file, and writes headers\n",
    "myFile = open(out_filename, \"w\")\n",
    "f = csv.writer(myFile)\n",
    "f.writerow(headers)\n",
    "\n",
    "for x in range(2012, 2018):\n",
    "    # URl to web scrap from: https://www.pro-football-reference.com/years/2012/fantasy.htm\n",
    "    # in this example we web scrap graphics cards from Newegg.com\n",
    "    page_url = \"https://www.pro-football-reference.com/years/\"+str(x)+\"/fantasy.htm\"\n",
    "\n",
    "    # opens the connection and downloads html page from url\n",
    "    uClient = uReq(page_url)\n",
    "\n",
    "    # parses html into a soup data structure to traverse html\n",
    "    # as if it were a json data type.\n",
    "    page_soup = soup(uClient.read(), \"html.parser\")\n",
    "    uClient.close()\n",
    "    \n",
    "    # finding all the Data needed\n",
    "    \n",
    "    findPlayers = page_soup.findAll(\"td\", {\"data-stat\": \"player\"})\n",
    "    allPlayers = [p.text.replace(\"*\",\"\").replace(\"+\",\"\") for p in findPlayers]\n",
    "    #<td class=\"left \" data-append-csv=\"PeteAd01\" data-stat=\"player\" csk=\"Peterson,Adrian\">\n",
    "    #    <a href=\"/players/P/PeteAd01.htm\">Adrian Peterson</a>*+\n",
    "    #</td>\n",
    "    \n",
    "    findPoints = page_soup.findAll(\"td\", {\"data-stat\": \"fantasy_points\"})\n",
    "    allPoints = [p.text for p in findPoints]\n",
    "    #<td class=\"right \" data-stat=\"fantasy_points\">307</td>\n",
    "    \n",
    "    findGames = page_soup.findAll(\"td\", {\"data-stat\": \"g\"})\n",
    "    allGames = [g.text for g in findGames]\n",
    "    #<td class=\"right \" data-stat=\"g\">16</td>\n",
    "    \n",
    "    currYear = [str(x) for i in range(len(allPoints))]\n",
    "    \n",
    "    tmp = [allPlayers, allGames, allPoints, currYear]\n",
    "    export_data = zip_longest(*tmp, fillvalue = '')\n",
    "    f.writerows(export_data)\n",
    "    #print(x)\n",
    "    \n",
    "\n",
    "myFile.close()  # Close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
