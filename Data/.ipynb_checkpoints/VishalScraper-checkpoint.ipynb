{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating out file: fantasyPoints2012.csv\n",
      "Scraping data for 2012\n",
      "Finished 2012\n",
      "Creating out file: fantasyPoints2013.csv\n",
      "Scraping data for 2013\n",
      "Finished 2013\n",
      "Creating out file: fantasyPoints2014.csv\n",
      "Scraping data for 2014\n",
      "Finished 2014\n",
      "Creating out file: fantasyPoints2015.csv\n",
      "Scraping data for 2015\n",
      "Finished 2015\n",
      "Creating out file: fantasyPoints2016.csv\n",
      "Scraping data for 2016\n",
      "Finished 2016\n",
      "Creating out file: fantasyPoints2017.csv\n",
      "Scraping data for 2017\n",
      "Finished 2017\n",
      "Finished Scraping All\n"
     ]
    }
   ],
   "source": [
    "# By Vishal Dubey\n",
    "from bs4 import BeautifulSoup as soup  # HTML data structure\n",
    "from urllib.request import urlopen as uReq  # Web client\n",
    "import csv # for writing to csv\n",
    "from itertools import zip_longest # for zipping lists together\n",
    "\n",
    "for x in range(2012, 2018):\n",
    "    \n",
    "    # name the output file to write to local disk\n",
    "    out_filename = \"fantasyPoints\"+str(x)+\".csv\"\n",
    "    \n",
    "    # header of csv file to be written\n",
    "    headers = [\"name\", \"position\", \"games\", \"points\", \"year\"]\n",
    "    print(\"Creating out file: \"+out_filename)\n",
    "    \n",
    "    # opens file, and writes headers\n",
    "    myFile = open(out_filename, \"w\")\n",
    "    f = csv.writer(myFile)\n",
    "    f.writerow(headers)\n",
    "\n",
    "    # URl to web scrap from: https://www.pro-football-reference.com/years/2012/fantasy.htm\n",
    "    # in this example we web scrap graphics cards from Newegg.com\n",
    "    page_url = \"https://www.pro-football-reference.com/years/\"+str(x)+\"/fantasy.htm\"\n",
    "\n",
    "    # opens the connection and downloads html page from url\n",
    "    uClient = uReq(page_url)\n",
    "\n",
    "    # parses html into a soup data structure to traverse html\n",
    "    # as if it were a json data type.\n",
    "    page_soup = soup(uClient.read(), \"html.parser\")\n",
    "    uClient.close()\n",
    "    \n",
    "    # finding all the Data needed\n",
    "    print(\"Scraping data for \"+str(x))\n",
    "    findPlayers = page_soup.findAll(\"td\", {\"data-stat\": \"player\"})\n",
    "    allPlayers = [p.text.replace(\"*\",\"\").replace(\"+\",\"\") for p in findPlayers]\n",
    "    #<td class=\"left \" data-append-csv=\"PeteAd01\" data-stat=\"player\" csk=\"Peterson,Adrian\">\n",
    "    #    <a href=\"/players/P/PeteAd01.htm\">Adrian Peterson</a>*+\n",
    "    #</td>\n",
    "    \n",
    "    findPoints = page_soup.findAll(\"td\", {\"data-stat\": \"fantasy_points\"})\n",
    "    allPoints = [p.text for p in findPoints]\n",
    "    #<td class=\"right \" data-stat=\"fantasy_points\">307</td>\n",
    "    \n",
    "    findGames = page_soup.findAll(\"td\", {\"data-stat\": \"g\"})\n",
    "    allGames = [g.text for g in findGames]\n",
    "    #<td class=\"right \" data-stat=\"g\">16</td>\n",
    "    \n",
    "    findPos = page_soup.findAll(\"td\", {\"data-stat\": \"fantasy_pos\"})\n",
    "    allPos = [p.text for p in findPos]\n",
    "    #<td class=\"right \" data-stat=\"fantasy_pos\" csk=\"20\">RB</td>\n",
    "    \n",
    "    currYear = [str(x) for i in range(len(allPoints))]\n",
    "    \n",
    "    tmp = [allPlayers, allPos, allGames, allPoints, currYear]\n",
    "    export_data = zip_longest(*tmp, fillvalue = '')\n",
    "    f.writerows(export_data)\n",
    "    print(\"Finished \"+str(x))\n",
    "    \n",
    "myFile.close()  # Close the file\n",
    "print(\"Finished Scraping All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
